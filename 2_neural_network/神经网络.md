# 一、神经网络

## 1.神经网络

- 定义：人工神经网络（Artificial Neural Network，ANN）也简称为神经网络（NN），是一种模仿生物神经网络结构和功能的计算模型。人脑可以看作是一个生物神经网络，由众多的神经元连接而成。各个神经元传递复杂的电信号，树突接收到输入信号，然后对信号进行处理，通过轴突输出信号。

- 神经网络中信息只向一个方向移动，即从输入节点向前移动，通过隐藏节点，再向输出节点移动。其中基本部分是：
  - 输入层：即输入x的那一层
  - 输出层：即输出y的那一层
  - 隐藏层：输入层和输出层之间都是隐藏层
- 特点：
  - 同一层神经网络之间没有连接
  - 第N层的每个神经元和第N-1层的所有神经元相连，这就是全连接神经网络（full connected,fc）
  - 第N-1层神经元的输出就是第N层神经元的输入
  - 每个连接都有一个权重值（w系数和b系数）

## 2.激活函数

- 激活函数用于对每层的输出数据（加权和数据）进行变换，进而为整个网络注入了非线性因素。此时，神经网络就可以拟合各种曲线
  - 没有引入非线性因素的网络等价于使用一个线性模型来拟合
  - 通过给网络输出增加激活函数，实现引入非线性因素，使得网络模型可以逼近任意函数，提升网络对复杂问题的拟合能力

### （1）sigmiod函数

- 公式：$f(x) = \frac{1}{1+e^{-x}}$
- 求导公式：$\begin{equation}
  f'(x)
  \end{equation}=f(x)(1-f(x))$

- 缺点：当神经网络的激活处于0， 1位置时，其梯度几乎为0，容易导致梯度消失，此时网络参数将更新极其缓慢，或者无法更新
- 一般来说，sigmoid网络在5层之类就会产生梯度消失现象。而且，该激活函数并不是以0为中心，所以在实践中很少使用这种激活函数，sigmoid函数一般只用于二分类的输出层

### （2）tanh激活函数

- 公式：$f(x) = \frac{1-e^{-2x}}{1+e^{-2x}}$
- 求导公式：$\begin{equation}
  f'(x)
  \end{equation}=1-f^2(x)$
- 其输出值域是（-1， 1），值域范围更大，使之更适合于神经网络的输入层和隐藏层
- 与sigmoid相比，它是以0为中心的，且梯度相对于sigmoid大，使得其收敛速度要比sigmoid快，减少迭代次数，但当输入值较大时，会导致梯度消失的问题
- 使用时：可在隐藏层使用tanh函数，在输出层使用sigmoid函数

### （3）ReLU激活函数

- 是目前使用最多的一种激活函数

- 公式：$f(x)=max(0, x)$
- 求导公式：$\begin{equation}
  f'(x)
  \end{equation}=0或1$

- 激活函数将小于0的值映射为0，而大于0的值则保持不变，它更加重视正信号，而忽略负信号，这种激活函数运算更为简单，能够提高模型的训练效率
- 当x<0时，ReLU导数为0，而当x>0时，则不存在饱和问题。所以，ReLU能够在x>0时保持梯度不衰减，从而缓解梯度消失问题。然而，随着训练的推进，部分输入会落入小于0的区域，导致对应权重无法更新，这种现象被称为“神经元死亡”
- ReLU是目前最常用的激活函数。与sigmoid相比，ReLU的优势是：采用sigmoid函数，计算量大（指数运算），反向传播球误差梯度时，计算量相对大，而采用ReLU激活函数，整个过程的计算量节省很多。sigmoid函数反向传播时，很容易出现梯度消失的情况，从而无法完成深度网络的训练。ReLU会使一部分神经元的输出为0，这样就造成了网络的稀疏性（网络变得简单），并且减少了参数的相互依存关系，缓解了过拟合问题的发生

### （4）Softmax函数

- softmax用于多分类过程中，它是二分类函数sigmoid在多分类上的推广，目的是将多分类的结果以概率形式呈现出来
- 公式：$softmax(z_i)=\frac{e^{z_i}}{\sum_je^z_j}$
  - $z_i$：输出层中每个神经元加权和（logits）

- Softmax就是将网络输出logits通过softmax函数，就映射成为（0，1）的值，而这些值的累和为1，那么我们将它理解成概率，选取概率最大（也就是值对应最大的节点），作为我们的预测目标类别

### （5）其他常见的激活函数



### （6）激活函数的选择方法

对于隐藏层

1. 优先选择ReLU激活函数
2. 如果ReLU效果不好，那么尝试其他激活，如Leaky ReLU等
3. 如果你使用了ReLU，需要注意一下Dead ReLU问题，避免出现大的梯度导致过多的神经元死亡
4. 少使用sigmoid激活函数，可以尝试使用tanh激活函数

对于输出层

1. 二分类问题选择sigmoid激活函数
2. 多分类问题选择softmax激活函数
3. 回归问题选择identity激活函数（恒等激活）

## 3.参数初始化

优先选择kaiming和xavier初始化方式

### （1）初始化$w$

- 均匀分布初始化：权重参数初始化从区间均匀随机取值。即在$(-\frac{1}{\sqrt d}, \frac{1}{\sqrt d})$均匀分布中生成当前神经元的权重，其中d为每个神经元的输入数量
- 正态分布初始化：随机初始化从均值为0，标准差是1的高斯分布中取样，使用一些很小的值对参数W进行初始化

### （2）初始化$b$

- 全0初始化：将神经网络中的所有权重参数初始化为0
- 全1初始化：将神经网络中的所有权重参数初始化为1
- 固定值初始化：将神经网络中的所有权重参数初始化为某个固定值

### （3）初始化方法改进

1. kaiming初始化，也叫做HE初始化
   - HE初始化分为正态分布的HE初始化，均匀分布的HE初始化
     - 正态分布的HE初始化：$stddev = \sqrt{\frac{2}{fan\_in}}$
     - 均匀分布的HE初始化：从[-limit, limit]中的均匀分布中抽取样本，limit是$\sqrt{\frac{6}{fan\_in}}$
     - $fan\_in$输入神经元个数
2. xavier初始化，也叫做Glorot初始化
   - Glorot初始化分为正态分布的xavier初始化，均匀分布的xavier初始化
     - 正态化的xavier初始化：$stddev=\sqrt{\frac{2}{fan\_in+fan\_out}}$
     - 均匀分布的Xavier初始化：从[-limit, limit]中的均匀分布中抽取样本，limit是$\sqrt{\frac{6}{fan\_in+fan\_out}}$
     - $fan\_in$是输入神经元个数，$fan\_out$是输出的神经元个数

## 4.神经网络搭建和参数计算

### （1）模型搭建

- 在pytorch中定义深度神经网络其实就是层堆叠的过程，继承自nn.Module，实现两个方法
  - \__init\\__ 方法中定义网络中的层结构，主要是全连接层，并进行初始化
  - forward方法，在实例化模型的时候，底层会自动调用该函数。该函数中可以定义学习率，为初始化定义的layer传入数据等。

### （2）网络参数量的统计方法

- 统计每一层中的权重w和偏置b的数量

```python
from torchsummary import summary
……
summary(my_modelll, input_size=(3, ), batch_size = 8)

for name, para in my_model.named_parameters():
    print(name)
    print(para)
```

## 5.神经网络优缺点

- 优点
  - 精度高，性能优于其他机器学习方法，甚至在某些领域超过了人类
  - 可以近似任意的非线性函数随之计算机硬件的发展
  - 近年来在学界和业界受到了热捧，有大量的框架和库可调
- 缺点
  - 黑箱，很难解释模型是怎么工作的
  - 训练时间长，需要大量的算力
  - 网络结构复杂，需要调整超参数
  - 小数据集上表现不佳，容易发生过拟合

# 二、损失函数

- 损失函数定义：损失函数是用来衡量模型参数的质量的函数，衡量方式是比较网络输出和真实输出的差异

- 别名：损失函数（loss function），代价函数（cost function），目标函数（objective function），误差函数（error function）

## 1.多分类损失函数

- 在多分类任务通常使用softmax将logits转换为概率的形式，所以多分类的交叉熵损失也叫做softmax损失，它的计算方法是：$L=-\sum_{i = 1}^ny_ilog(S(f_\theta(x_i)))$
  - $y_i$：真实值标签（one_hot热编码）
  - $f(x)$是样本属于某一类别的预测分数
  - $S(f_\theta(x_i))$：网络输出结果的概率值
  - $i=1$：样本个数
- 在pytorch中使用nn.CrossEntropyLoss()实现

## 2.二分类任务损失函数

- 在处理二分类任务时， 使用sigmoid激活函数，则损失函数也会进行相应的调整，使用二分类的交叉熵损失函数：$L = -ylog\hat y-(1-y)log(1-\hat y)$
  - y是样本x中属于某一个类别的真实概率
  - $\hat y$是严格不能属于某一类别的预测概率
  - $L$用来衡量真实值y与预测值$\hat y$之间的差异性的损失结果
- 在pytorch中使用nn.BCELoss()实现

## 3.回归任务损失函数-MAE损失函数

- Mean absolute loss（MAE）也被称为L1 Loss，是以绝对误差作为距离，损失函数公式：$L = \frac{1}{n}\sum_{i = 1}^n|y_i=f_\theta(x_i)|$
- 特点：
  - 由于L1 loss具有稀疏性，为了惩罚较大的值，因此常常将其作为正则项添加到其他loss中作为约束；
  - L1 loss的最大问题时梯度在零点不平滑，导致会跳过极小值（最优解）

## 4.回归任务损失函数-MSE损失函数

- Mean Squared Loss/Quadratic Loss(MSE loss)也被称作L2 loss，或欧氏距离，它以误差的平方和的均值作为距离损失函数公式：$L = \frac{1}{n}\sum_{i = 1}^n(y_i-f_{\theta(x_i)})^2$
- 特点：
  - L2 loss也常常作为正则项
  - 当预测值与目标值相差很大时，梯度容易爆炸（则尽量不会使用这种损失函数）

## 5.回归任务损失函数-smooth L1损失函数

- smooth L1说的是光滑之后的L1，损失函数公式为：$
  \text{smooth}_{L_1}(x) = 
  \begin{cases} 
  0.5x^2 & \text{if } \vert x \vert < 1 \\
  \vert x \vert - 0.5 & \text{otherwise}
  \end{cases}$
  - 其中，$x = f(x)-y$为真实值与预测值的差值
- 从图像中可以看出，该函数实际上就是一个分段函数
  - 在$[-1, 1]$之间实际上就是L2损失，这样解决了L1的不光滑问题
  - 在$[-1, 1]$区间外，实际上就是L1损失，这样就解决了离群点梯度爆炸的问题

# 三、网络优化方法

## 1.梯度下降算法

- 梯段下降算法是一种寻找使损失函数最小化的方法，从数学上的角度来看，梯度的方向是函数增长速度最快的方向，那么梯度的反方向就是函数减少最快的方向，所以有$W_{ij}^{new} = W_{ij}^{old}-\eta\frac{\partial E}{\partial W_{ij}}$
  - 其中，$\eta$是学习率，如果学习率太小，那么每次训练之后得到的效果都太小，增大训练的时间成本；如果学习率太大，那就有可能直接跳过最优解，进入无限的训练中。解决的方法就是，学习率也需要随着训练的进行而变化

- 在进行模型训练的时候，有三个基础的概念
  - $Epoch$：使用全部数据对模型进行一次完整训练，训练轮次
  - $Batch\_size$：使用训练集中的小部分样本对模型权重进行以此反向传播的参数更新，每次训练每批次样本的数量（越大越好）
  - $Iteraion$：使用一个Batch数据对模型进行一次参数更新的过程
  - $eg.$：假设数据集有$50000$个训练样本，现在选择$Batch Size= 256$对模型进行训练，每个$Epoch$要训练的图片数量为$50000$，训练集具有$Batch$个数为$50000/256 + 1 = 196$；每个$Epoch$具有的$Iteration$个数为$196$；$10$个$Epoch$具有的$Iteration$个数为$1960$

- 在深度学习中，梯度下降的几种方式的根本区别就在于Batch Size不同

  | 梯度下降方式 | Training Set  Size | Batch Size | Number of Batch |
  | :----------: | :----------------: | :--------: | :-------------: |
  |     BGD      |         N          |     N      |        1        |
  |     SGD      |         N          |     1      |        N        |
  |  Mini-Batch  |         N          |     B      |    N / B + 1    |

  - 注：N/ B+ 1是针对未整除的情况。整除则是 N/ B
  - 在工作的时候通常使用的是 Mini-Batch

## 2.反向传播算法过程

### （1）反向传播（BP算法）

- 前向传播：指的是数据输入的神经网络中，逐层向前传输，一直运算到输出层为止
- 反向传播（BackPropagation）：利用损失函数ERROR，从后往前，结合梯度下降算法，依次求各个参数的偏导并进行参数更新
- 解释：
  1. 前向传播：获取预测结果
  2. 计算损失：交叉熵/MSE（先计算$W_3$，再计算$W_2$，最后计算$W_1$)
  3. 反向传播：利用梯度下降算法对参数进行更新

```python
for _ in range(epochs):
    for train_x, train_y in dataloader:
        # 将一个batch的训练数据送入模型
        y_pred = model(train_x.type(torch.float32))
        # 计算损失值
        loss = criterion(y_pred, train_y, reshape(-1,1).type(torch.float32))
        total_loss += loss.item()
        train_sample += len(train_y)
        # 梯度清零
        optimizer.zero_grad()
        # 自动微分
        loss.backward()
        # 更新参数
        optimizer.step()
```

## 3.梯度下降的优化方法

- 梯度下降优化算法中，可能会碰到以下情况：

- - 碰到平缓区域，梯度值较小，参数优化变慢
  - 碰到鞍点，梯度为0，参数无法优化
  - 碰到局部最小值，参数不是最优

- 对于这些问题，出现了一些对梯度下降算法的优化方法，例如：Momentum， AgaGrad，PMSprop，Adam等

### （1）指数加权平均

- 指数移动加权平均：参考各数值，并且各数值的权重都不同，距离越远的数字对平均数计算的贡献就越小（权重较小），距离越近则对平均数的计算贡献就越大（权重越大）
- 计算公式：$${s}_t = 
  \begin{cases} 
  \displaystyle Y_1, & t = 0 \\
  \displaystyle \beta \cdot {s}_{t-1} + (1 - \beta) \cdot Y_t, & t > 0 
  \end{cases}$$
- - $S_t$表示指数加权平均值
  - $Y_t$表示$t$时刻的值
  - $\beta$调整权重参数，该值越大平均数越平缓

### （2）动量算法Momentum

- 梯度计算公式：$D_t = \beta \cdot S_{t - 1} + (1-\beta) \cdot W_t$
  - $S_{t - 1}$表示；表示梯度移动加权平均值
  - $W_t$表示当前时刻的梯度值
  - $D_t$为当前时刻的梯度值
  - $\beta$为权重系数
  - 示例：权重$\beta$为0.9， 则第一次梯度值$S_1 = D_1 = W_1$；第二次梯度值$D_2 = S_2 = 0.9 \times S_1 + W_2 \times0.1$；第三次梯度值$D_3 = S_3 = 0.9 \times S_2 + W_3 \times 0.1$；第四次梯度值$D_4 = S_4 = 0.9 \times S_3 + W_4 \times 0.1$
- 梯度下降公式中梯度的计算，就不再是当前时刻t的梯度值，而是历史梯度值的指数移动加权平均值，公式修改为：$W_{t + 1} = W_t - \alpha \cdot D_t$

**拓展**：Monmentum优化方法是如何一定程度上克服“平缓”，“鞍点”的问题呢？

- 当处于鞍点位置时，由于当前的梯度为0，参数无法更新。但是Momentum动量梯度下降算法已经在先前累计了一些梯度值，很有可能使得跨过鞍点
- 由于mini-batch普通的梯度下降算法，每次选取少数的样本梯度确定前进方向，可能会出现震荡，使得训练时间变长。Momentum使用移动加权平均，平滑了梯度的变化，使得前进方向更加平缓，有利于加快训练过程

```python
"""加了动量之后的结果"""

import torch

w = torch.tensor([1.0], requires_grad=True, dtype=torch.float32)

loss = ((w ** 2)*0.5).sum()

optimizer = torch.optim.SGD([w], lr = 0.01, momentum=0.9)

optimizer.zero_grad()
loss.backward()
optimizer.step()

print("第一次更新（加了动量之后）梯度：",w.grad)
print("第一次更新（加了动量之后）w：",w.detach())

loss = ((w ** 2)*0.5).sum()
optimizer.zero_grad()
loss.backward()
optimizer.step()

print("第二次更新（加了动量之后）梯度：",w.grad)
print("第二次更新（加了动量之后）w：",w.detach()) # tensor([0.9711])改变了，没加动量时 tensor([0.9801])

"""tensor([0.9900])--->tensor([0.9711])   减少得更多，更新得更加快一点"""
```

输出结果：

```lua
第一次更新（加了动量之后）梯度： tensor([1.])
第一次更新（加了动量之后）w： tensor([0.9900])
第二次更新（加了动量之后）梯度： tensor([0.9900])
第二次更新（加了动量之后）w： tensor([0.9711])
```

### （3）AdaGrad

- AdaGrad通过对不同的参数分量使用不同的学习率，AdaGrad的学习率总体会逐渐减小，计算步骤如下

  1. 初始化学习率$\alpha$，初始化参数$\theta$（weight&bias）小常数$\sigma = 1e - 6$（放在分母上，防止分母为0）

  2. 初始化梯度累计变量$s = 0$

  3. 从训练集中采样$m$个样本的小批量，计算梯度$g$

  4. 累积平方梯度${s} = {s} + {g} \odot {g}$，$\odot$表示各个分量相乘

  - 学习率$\alpha$的计算公式如下：$\alpha = \frac{\alpha}{\sqrt s + \sigma}$

  - 参数更新公式如下：$\theta = \theta - \frac{\alpha}{\sqrt s + \sigma} \cdot g$

重复2-4步骤，即可完成网络训练

- AdaGrad缺点：可能会使得学习率过早，过量的降低（学习率太小了，则更新速度变慢了，迭代相同次数就不能够到最优解），导致训练后期学习率大小较难找到最优解

```python
import torch

w = torch.tensor([1.0], requires_grad=True, dtype=torch.float32)
loss = ((w ** 2)*0.5).sum()

optimizer = torch.optim.Adagrad([w], lr = 0.01)

optimizer.zero_grad()
loss.backward()

print("第一次更新  梯度：",w.grad) # 获取梯度的值
print("第一次更新  w：",w.detach()) # 获取w的值

# 再次更新参数
loss = ((w ** 2)*0.5).sum()
optimizer.zero_grad()
loss.backward()
optimizer.step()

print("第二次更新  梯度：",w.grad) # 获取梯度的值
print("第二次更新  w：",w.detach()) # 获取w的值
```

输出结果：

```lua
第一次更新  梯度： tensor([1.])
第一次更新  w： tensor([1.])
第二次更新  梯度： tensor([1.])
第二次更新  w： tensor([0.9900])
```

### （4）RMSProp

- RMSProp优化算法是对AdaGrad的优化，最主要的不同是，其使用**指数移动加权平均梯度**替换历史梯度的平方和。计算过程如下：

  1. 初始化学习率$\alpha$，初始化参数$\theta$，小常数$\sigma = 1e-6$
  2. 初始化参数$\theta$
  3. 初始化梯度累计变量$s$
  4. 从训练集中采样$m$个样本的小批量，计算梯度$g$
  5. 使用指数移动平均累积历史梯度，公式如下：$s = \beta \cdot s + (1 - \beta)g \odot g$

  - 学习率$\alpha$的计算公式如下：$\alpha = \frac{\alpha}{\sqrt s + \sigma}$
  - 参数更新公式如下：$\theta = \theta - \frac{\alpha}{\sqrt s + \sigma} \cdot g$

```python
import torch

w = torch.tensor([0.1], requires_grad=True, dtype = torch.float32)
loss = ((w ** 2)*0.5).sum()

optimizer = torch.optim.RMSprop([w], lr = 0.01, alpha = 0.9)

optimizer.zero_grad()
loss.backward()

print("第一次更新 梯度：", w.grad)
print("第一次更新 w：", w.detach())

# 再次更新参数
loss = ((w ** 2)*0.5).sum()
optimizer.zero_grad()
loss.backward()
optimizer.step()

print("第二次更新  梯度：",w.grad) # 获取梯度的值
print("第二次更新  w：",w.detach()) # 获取w的值
```

输出结果：

```lua
第一次更新 梯度： tensor([0.1000])
第一次更新 w： tensor([0.1000])
第二次更新  梯度： tensor([0.1000])
第二次更新  w： tensor([0.0684])
```

## 4.学习率衰减方法

- 通常是和  动量算法Momentum  组合在一起
- 后面学习中，通常使用指定间隔学习率衰减

### （1）等间隔学习率衰减

```python
import torch
import matplotlib.pyplot as plot

# 参数初始化
LR = 0.1
iteration = 100
epochs = 200
# 网络数据初始化
x = torch.tensor([1.0])
w = torch.tensor([1.0], requires_grad = True)
y = torch.tensor([1.0])
# 优化器
optimizer = torch.optim.SGD([w], lr = LR, momentum=0.9)
# 学习率策略
scheduler_lr = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma = 0.8)
# 遍历轮次
epoch_list = []
lr_list = []
for epoch in range(epochs):
    lr_list.append(scheduler_lr.get_last_lr())
    epoch_list.append(epoch)

    # 遍历batch
    for i in range(iteration):
        # 计算损失
        loss = ((w*x-y)**2)*0.5
        # 更新参数
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    # 更新lr
    scheduler_lr.step()
# 绘制结果
plt.plot(epoch_list, lr_list)
plt.grid()
plt.show()
```

### （2）指定间隔学习率衰减

```python
import torch
import matplotlib.pyplot as plot

# 参数初始化
LR = 0.1
iteration = 100
epochs = 200
# 网络数据初始化
x = torch.tensor([1.0])
w = torch.tensor([1.0], requires_grad = True)
y = torch.tensor([1.0])
# 优化器
optimizer = torch.optim.SGD([w], lr = LR, momentum=0.9)
# 学习率策略
scheduler_lr = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones = [20, 60, 90, 135, 180], gamma = 0.8)
# 遍历轮次
epoch_list = []
lr_list = []
for epoch in range(epochs):
    lr_list.append(scheduler_lr.get_last_lr())
    epoch_list.append(epoch)

    # 遍历batch
    for i in range(iteration):
        # 计算损失
        loss = ((w*x-y)**2)*0.5
        # 更新参数
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    # 更新lr
    scheduler_lr.step()
# 绘制结果
plt.plot(epoch_list, lr_list)
plt.grid()
plt.show()
```

### （3）按指数学习率衰减

- 这种策略用得很少，一般不会选择
- gamma值通常是小于1，它是指  指数的底
- 调整方式：$lr = lr \cdot gamma^{epoch}$

```python
import torch
import matplotlib.pyplot as plot

# 参数初始化
LR = 0.1
iteration = 100
epochs = 200
# 网络数据初始化
x = torch.tensor([1.0])
w = torch.tensor([1.0], requires_grad = True)
y = torch.tensor([1.0])
# 优化器
optimizer = torch.optim.SGD([w], lr = LR, momentum=0.9)
# 学习率策略
scheduler_lr = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.8)
# 遍历轮次
epoch_list = []
lr_list = []
for epoch in range(epochs):
    lr_list.append(scheduler_lr.get_last_lr())
    epoch_list.append(epoch)

    # 遍历batch
    for i in range(iteration):
        # 计算损失
        loss = ((w*x-y)**2)*0.5
        # 更新参数
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    # 更新lr
    scheduler_lr.step()
# 绘制结果
plt.plot(epoch_list, lr_list)
plt.grid()
plt.show()
```

# 四、正则化方法

- 在深度学习中，所有能够缓解网络过拟合的方法都叫做正则化方法（越复杂的模型越容易发生过拟合）

- 在设计机器学习算法时希望在新样本上的泛化能力强。许多机器学习算法都采用相关的策略来减小测试误差，这些策略统称为正则化
- 神经网络的强大的表示能力经常遇到过拟合，所以需要使用不同形式的正则化策略
- 目前深度学习中使用较多的策略有**范数惩罚**，**DropOut**, **特殊的网络层**等。

## 1.范数惩罚（L1， L2）

### （1）L1正则化

会直接把高次项前面的系数变为0

- 定义：在损失函数中添加L1范数作为正则化项，公式为$J(w) = MSE(w)+\alpha \sum_{i = 1}^n|w_i|$
- 惩罚系数

- - $\alpha$控制正则化强度，值越大惩罚力度越大
  - 属于需要人工调整的超参数

- 权重影响

- - 通过绝对值函数的梯度特性（x>0导数为1，x<0导数为-1）迫使权重趋向0
  - 可能使不重要的特征权重精确等于0，实现特征筛选

- 应用场景

- - 适用于需要特征选择的场景
  - 加入线性回归后形成Lasso回归模型

- 优化过程

- - 初始化权重后，正则化项的负梯度方向会持续推动权重向0靠近
  - 当权重=0时梯度消失，优化停止

- 使用L1正则化的线性回归模型就是Lasso回归

### (2）L2正则化（优先选择）

- 公式：$J(w) = MSE(w)+\alpha \sum_{i = 1}^nw_i^2$

- - $\alpha$叫做惩罚系数，该值越大则权重调整幅度就越大，即表示对特征权重惩罚力度就越大

- L2正则化会使得权重趋向于0，一般不等于0
- 使用L2正则化的线性回归模型是**岭回归**

## **2.DropOut正则化（随机失活）**

- 在训练时候用，在预测的时候一定不能将其中某些层失活掉（即在测试过程中，随机失活不起作用）
- 在训练神经网络中模型参数较多，在数据量不足的情况下，很容易发生过拟合，DropOut（随机失活）是一种有效的正则化方法
- 在训练过程中，DropOut的实现是让神经元以超参数p的概率停止工作或者激活被置为0， 未被置为0的进行缩放，缩放比例为$\frac{1}{1-p}$（实质上是增大比例）。训练过程可以认为是对完整的神经网络的一些子集进行训练，每次基于输入数据只更新子网络的参数

```python
import torch
import torch.nn as nn

torch.random.manual_seed(22)
input = torch.randn([1, 4])
layer = nn.Linear(in_features=4, out_features=5)
y = layer(input)
print(y)

dropout = nn.Dropout(p = 0.75)
out = dropout(y)
print(out)
```

## 3.批量归一化（BN层）

- 在计算机视觉（CV）中使用较多

先对**数据标准化**，再对**数据重构**（缩放+平移）：$f(x) = \lambda \cdot \frac{x - E(x)}{\sqrt{Var(x)}+\epsilon}+\beta$

- $\lambda$和$\beta$是可学习的参数，它相当于对标准化后的值做了一个**线性变换**，$\lambda$为系数，$\beta$为偏置
- $eps$通常指为$1e-5$，避免分母为$0$
- $E(x)$表示变量的均值
- $Var(x)$表示变量的方差
